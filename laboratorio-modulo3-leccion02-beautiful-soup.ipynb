{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"https://github.com/Hack-io-Data/Imagenes/blob/main/01-LogosHackio/logo_naranja@4x.png?raw=true\" alt=\"esquema\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contexto\n",
    "\n",
    "**Descripción:**\n",
    "\n",
    "SetMagic Productions es una empresa especializada en la provisión de servicios integrales para la realización de rodajes cinematográficos y audiovisuales. Nos dedicamos a facilitar tanto el atrezzo necesario para las producciones como los lugares idóneos para llevar a cabo los rodajes, ya sea en entornos al aire libre o en interiores.\n",
    "\n",
    "**Servicios Ofrecidos:**\n",
    "\n",
    "- **Atrezzo Creativo:** Contamos con un extenso catálogo de atrezzo que abarca desde accesorios hasta muebles y objetos temáticos para ambientar cualquier tipo de  escena.\n",
    "\n",
    "- **Locaciones Únicas:** Nuestra empresa ofrece una amplia selección de locaciones, que incluyen desde escenarios naturales como playas, bosques y montañas, hasta espacios interiores como estudios, casas históricas y edificios emblemáticos.\n",
    "- **Servicios de Producción:** Además de proporcionar atrezzo y locaciones, también ofrecemos servicios de producción audiovisual, incluyendo equipos de filmación, personal técnico y servicios de postproducción.\n",
    "\n",
    "**Herramientas y Tecnologías:**\n",
    "\n",
    "Para recopilar información sobre nuevas locaciones y tendencias en atrezzo, utilizamos herramientas de web scraping como Beautiful Soup y Selenium para extraer datos de sitios web relevantes y redes sociales especializadas en cine y producción audiovisual. También integramos APIs de plataformas de alquiler de locaciones y bases de datos de atrezzo para acceder a información actualizada y detallada.\n",
    "\n",
    "**Almacenamiento de Datos:** (A trabajar la próxima semana)\n",
    "\n",
    "La información recopilada mediante web scraping y APIs se almacenará tanto en una base de datos relacional SQL como en una base de datos no relacional MongoDB . Estas base de datos nos permite organizar eficientemente la información sobre locaciones, atrezzo, clientes y proyectos en curso, facilitando su acceso y gestión.\n",
    "\n",
    "**Objetivo:**\n",
    "\n",
    "Nuestro objetivo principal es proporcionar a nuestros clientes una experiencia fluida y personalizada en la búsqueda y selección de locaciones y atrezzo para sus proyectos audiovisuales. Utilizando tecnologías avanzadas y una amplia red de contactos en la industria, nos esforzamos por ofrecer soluciones creativas y de alta calidad que satisfagan las necesidades específicas de cada producción.\n",
    "\n",
    "\n",
    "## Lab: Extracción de Información con Beautiful Soup\n",
    "\n",
    "En este laboratorio seguirás enriqueciendo la base de datos para ofrecer a tus clientes un servicio más completo y personalizado. Para lograr esto, extraerás información valiosa sobre objetos de atrezzo de una web especializada. Utilizarás técnicas de web scraping con la biblioteca **Beautiful Soup** para obtener y organizar los datos de manera eficiente.\n",
    "\n",
    "Trabajarás con la siguiente URL: [Atrezzo Vázquez](https://atrezzovazquez.es/shop.php?search_type=-1&search_terms=&limit=48&page=1). Esta página contiene una gran cantidad de objetos de atrezzo que pueden ser de interés para un proyecto de rodaje. Tu tarea será extraer información relevante de los productos listados en las primeras 100 páginas.\n",
    "\n",
    "1. **Navegación y Extracción de Múltiples Páginas**:\n",
    "\n",
    "   - La página web contiene varios elementos distribuidos en distintas páginas. Tu objetivo será iterar a través de las 100 primeras páginas y extraer la información deseada.\n",
    "\n",
    "   - Debes asegurarte de que tu código sea capaz de navegar automáticamente por estas páginas y extraer datos de manera continua.\n",
    "\n",
    "2. **Verificación del Código de Estado de la Respuesta**:\n",
    "\n",
    "   - Antes de extraer cualquier información, es fundamental verificar que la solicitud a la página web ha sido exitosa. Un código de estado 200 indica que la página se ha cargado correctamente.\n",
    "\n",
    "   - Si el código no es 200, debes imprimir un mensaje de error y detener la ejecución de la extracción para evitar problemas posteriores.\n",
    "\n",
    "3. **Extracción de Información Específica**:\n",
    "\n",
    "   De cada página, deberás extraer los siguientes detalles de los objetos de atrezzo:\n",
    "\n",
    "   - **Nombre del Objeto**: El nombre o identificador del objeto.\n",
    "\n",
    "   - **Categoría**: La categoría en la que se clasifica el objeto (ej.: mobiliario, decorado, utilería, etc.).\n",
    "\n",
    "   - **Sección**: La sección específica dentro de la categoría.\n",
    "\n",
    "   - **Descripción**: Una breve descripción del objeto que puede incluir detalles sobre su estilo, material o uso.\n",
    "\n",
    "   - **Dimensiones**: El tamaño del objeto en formato (largo x ancho x alto).\n",
    "\n",
    "   - **Enlace a la Imagen**: El link a la imagen del objeto, útil para tener una vista previa visual.\n",
    "\n",
    "4. **Organización de los Datos en un Diccionario**:\n",
    "\n",
    "   Una vez extraída la información, deberás organizarla en un diccionario con las siguientes claves:\n",
    "\n",
    "   - `\"nombre\"`: Nombres del objeto.\n",
    "\n",
    "   - `\"categoria\"`: Categoría a la que pertenece el objeto.\n",
    "\n",
    "   - `\"seccion\"`: Sección específica dentro de la categoría.\n",
    "\n",
    "   - `\"descripcion\"`: Breve descripción del objeto.\n",
    "\n",
    "   - `\"dimensiones\"`: Dimensiones del objeto en el formato adecuado.\n",
    "\n",
    "   - `\"imagen\"`: URL de la imagen del objeto.\n",
    "\n",
    "5. **Almacenamiento de la Información en un DataFrame**:\n",
    "\n",
    "   Una vez que tengas toda la información organizada en diccionarios, el siguiente paso es convertirla en un DataFrame de Pandas. Este DataFrame te permitirá manipular y analizar los datos con facilidad. Tu DataFrame debería verse similar al ejemplo proporcionado, donde cada fila representa un objeto diferente y cada columna contiene la información extraída:\n",
    "\n",
    "![Dataframe](https://github.com/Hack-io-Data/Imagenes/blob/main/02-Imagenes/BS/df_atrezzo.png?raw=true)\n",
    "\n",
    "\n",
    "6.  Consideraciones Adicionales:\n",
    "\n",
    "- Asegúrate de manejar posibles errores o excepciones durante el scraping, como tiempos de espera agotados, páginas inaccesibles o datos faltantes.\n",
    "\n",
    "- Recuerda que el scraping debe hacerse de manera respetuosa, evitando sobrecargar el servidor de la página web (puedes usar pausas entre solicitudes).\n",
    "\n",
    "- Finalmente, asegúrate de almacenar el DataFrame en un archivo CSV para que puedas reutilizar esta información en análisis futuros.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importar librerías\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info(clave, obj):\n",
    "\n",
    "    if clave == 'Nombre':\n",
    "        return obj.findAll('a', {'class': 'title'})[0].getText()\n",
    "\n",
    "    elif clave == 'Categoria':\n",
    "        return obj.findAll('a', {'class': 'tag'})[0].getText()\n",
    "    \n",
    "    elif clave == 'Seccion':\n",
    "        return obj.findAll('div', {'class': 'cat-sec'})[0].getText()\n",
    "    \n",
    "    elif clave == 'Descripcion':\n",
    "        return obj.findAll('div', {'class': 'article-container style-1'})[0].getText().strip('\\n')\n",
    "    \n",
    "    elif clave == 'Dimensiones':\n",
    "        return obj.findAll('div', {'class': 'price'})[0].getText().strip('\\n')\n",
    "    \n",
    "    elif clave == 'Imagen':\n",
    "        return obj.findAll('div', {'class': 'price'})[0].getText().strip('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def llenar_objetos(items, lista_dc = []):\n",
    "\n",
    "    # Lista de categorías\n",
    "    claves = ['Nombre', 'Categoria', 'Seccion', 'Descripcion', 'Dimensiones', 'Imagen']\n",
    "\n",
    "    # Recorremos cada item de los items\n",
    "    for item in items: \n",
    "\n",
    "        # Definimos un diccionario vacío\n",
    "        dc = {}\n",
    "\n",
    "        # Llenamos el diccionario con la información que haya disponible\n",
    "        for clave in claves:\n",
    "            try:\n",
    "                dc[clave] = get_info(clave, item)\n",
    "            except:\n",
    "                dc[clave] = None\n",
    "\n",
    "        # Añadimos el diccionario lleno a la lista\n",
    "        lista_dc.append(dc)\n",
    "\n",
    "    # Devolvemos la lista\n",
    "    return lista_dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "pagina = 1\n",
    "\n",
    "url_atr = f'https://atrezzovazquez.es/shop.php?search_type=-1&search_terms=&limit=48&page={pagina}'\n",
    "\n",
    "response_atr = requests.get(url_atr)\n",
    "\n",
    "if response_atr.status_code == 200:\n",
    "    print('ok')\n",
    "\n",
    "else:\n",
    "    print(f'Status code: {response_atr.status_code}')\n",
    "\n",
    "sopa_atr = BeautifulSoup(response_atr.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rascar_pagina(pagina, lista_dc=[]):\n",
    "\n",
    "    # URL\n",
    "    url_atr = f'https://atrezzovazquez.es/shop.php?search_type=-1&search_terms=&limit=48&page={pagina}'\n",
    "\n",
    "    # Petición\n",
    "    response_atr = requests.get(url_atr)\n",
    "\n",
    "    # Si la respuesta está bien\n",
    "    if response_atr.status_code == 200:\n",
    "        print(f'Éxito: código {response_atr.status_code}')\n",
    "\n",
    "    # Si no está bien salimos\n",
    "    else:\n",
    "        return f'Status code: {response_atr.status_code}'\n",
    "\n",
    "    # Sopa\n",
    "    sopa_atr = BeautifulSoup(response_atr.content, 'html.parser')\n",
    "\n",
    "    # Sacamos los objetos de la página\n",
    "    objetos = sopa_atr.findAll(\"div\", {'class': \"col-md-3 col-sm-4 shop-grid-item\"})\n",
    "\n",
    "    return llenar_objetos(objetos, lista_dc=lista_dc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Éxito: código 200\n",
      "Éxito: código 200\n",
      "Éxito: código 200\n",
      "Éxito: código 200\n",
      "Éxito: código 200\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "\n",
    "    dic = rascar_pagina(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "528"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dic)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
